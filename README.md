# Web-crawler 
This repository contains a web crawler that will extract the most important words from the pages it crawls. Given an initial url, a depth
and a maximum time it will crawl the given page and its surrounding pages up to the specified depth and store the retrieved information in csv files.

To run this application, open the `pom.xml` in I
ntellij or similar. The depth, time and starturl can be set in the `main` method.